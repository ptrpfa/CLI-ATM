{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Configurations \"\"\"\n",
    "# Imports\n",
    "import os, re, json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# # Google Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "# %cd /content/drive/My Drive/Colab Notebooks/\n",
    "\n",
    "# Settings\n",
    "# Files\n",
    "filepath = \"files\"\n",
    "dataset_file = \"%s/excel/bank.xlsx\" % filepath\n",
    "output_dataset_file = \"%s/excel/processed_bank.xlsx\" % filepath\n",
    "output_accounts_file = \"%s/excel/accounts.xlsx\" % filepath\n",
    "pklfile_accounts = \"%s/pickles/accounts.pkl\" % filepath\n",
    "pklfile_dataset = \"%s/pickles/dataset.pkl\" % filepath\n",
    "\n",
    "# Columns\n",
    "column_mappings = { \n",
    "                    \"Account No\": \"AccountNo\", \n",
    "                    \"DATE\": \"ValueDate\", \n",
    "                    \"TRANSACTION DETAILS\": \"Remarks\", \n",
    "                    \"CHQ.NO.\": \"ChequeNo\", \n",
    "                    \"VALUE DATE\": \"Date\",\n",
    "                    \"WITHDRAWAL AMT\": \"Credit\", \n",
    "                    \"DEPOSIT AMT\": \"Debit\", \n",
    "                    \"BALANCE AMT\": \"Balance\"\n",
    "                }\n",
    "column_order = [\"TransactionNo\", \"AccountNo\", \"ChequeNo\", \"Date\", \"ValueDate\", \"Debit\", \"Credit\", \"Status\", \"Balance\", \"Remarks\"]\n",
    "\n",
    "# Functions\n",
    "# Function to pickle object (accepts object to pickle and its filename to save as)\n",
    "def pickle_object (pickle_object, filepath):\n",
    "    # Create file object to store object to pickle\n",
    "    file_pickle = open (filepath, 'wb') # w = write, b = bytes (overwrite pre-existing files if any)\n",
    "\n",
    "    # Pickle (serialise) object [store object as a file]\n",
    "    pickle.dump (pickle_object, file_pickle)\n",
    "\n",
    "    # Close file object\n",
    "    file_pickle.close ()\n",
    "\n",
    "# Function to load pickle object (accepts filename of pickle to load and returns the de-pickled object)\n",
    "def load_pickle (filepath):\n",
    "    # Create file object accessing the pickle file\n",
    "    file_pickle = open (filepath, 'rb') # r = read, b = bytes\n",
    "\n",
    "    # Get pickled object\n",
    "    pickled_object = pickle.load (file_pickle)\n",
    "\n",
    "    # Close file object\n",
    "    file_pickle.close ()\n",
    "\n",
    "    # Return pickle object\n",
    "    return pickled_object\n",
    "\n",
    "\"\"\" Program Entrypoint \"\"\"\n",
    "# Read dataset file\n",
    "df_dataset = pd.read_excel(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Preliminary Processing \"\"\"\n",
    "# Drop . column\n",
    "df_dataset.drop(axis = 1, columns = \".\", inplace = True) \n",
    "\n",
    "# Remove duplicate row entries\n",
    "df_dataset.drop_duplicates(inplace = True)\n",
    "\n",
    "# Reset index\n",
    "df_dataset.index = range(len(df_dataset.index))\n",
    "\n",
    "# Create TransactionNo column\n",
    "df_dataset['TransactionNo'] = df_dataset.index + 1\n",
    "\n",
    "# Create Status column (set all transactions to be successful)\n",
    "df_dataset['Status'] = 1\n",
    "\n",
    "# Rename columns\n",
    "df_dataset.rename(columns = column_mappings, inplace = True)\n",
    "\n",
    "# Rearrange columns\n",
    "df_dataset = df_dataset[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Data Processing \"\"\"\n",
    "# Remove trailling '\n",
    "df_dataset['AccountNo'] = df_dataset['AccountNo'].str.strip(\"'\")\n",
    "\n",
    "# Format dates\n",
    "df_dataset['Date'] = df_dataset['Date'].dt.strftime(\"%d/%m/%Y\")\n",
    "df_dataset['ValueDate'] = df_dataset['ValueDate'].dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "# Loop through each row to update the formatting of account, transaction and cheque numbers \n",
    "for index in df_dataset.index:\n",
    "  # AccountNo formatting\n",
    "  if(len(df_dataset.loc[index]['AccountNo']) == 7): #  Check length of account no\n",
    "      df_dataset.at[index, 'AccountNo'] = \"40900\" + df_dataset.loc[index]['AccountNo']\n",
    "\n",
    "  # TransactionNo formatting\n",
    "  df_dataset.at[index, 'TransactionNo'] = \"{:0>8}-{}-{}\".format(df_dataset.loc[index]['TransactionNo'], re.search(\"^\\d{2}\\/(\\d{2})\\/(\\d{4})$\", df_dataset.loc[index]['Date']).group(1), re.search(\"^\\d{2}\\/(\\d{2})\\/(\\d{4})$\", df_dataset.loc[1]['Date']).group(2))\n",
    "\n",
    "  # ChequeNo formatting\n",
    "  if(not pd.isna(df_dataset.loc[index]['ChequeNo'])):\n",
    "    df_dataset.at[index, 'ChequeNo'] = \"{:0>6}:{}:{}\".format(int(df_dataset.loc[index]['ChequeNo']), df_dataset.loc[index]['Date'].replace(\"/\", \"\")[2:], df_dataset.loc[index]['AccountNo'])\n",
    "\n",
    "\"\"\" Anomaly Handling \"\"\"\n",
    "# Swap Date and ValueDate values of record with TransactionNo = 00063319-05-2017\n",
    "df_dataset.loc[df_dataset['TransactionNo'] == \"00063319-05-2017\", \"Date\"], df_dataset.loc[df_dataset['TransactionNo'] == \"00063319-05-2017\", \"ValueDate\"] = df_dataset.loc[df_dataset['TransactionNo'] == \"00063319-05-2017\", \"ValueDate\"], df_dataset.loc[df_dataset['TransactionNo'] == \"00063319-05-2017\", \"Date\"]\n",
    "\n",
    "# Set status of suspected fraudulent transactions to failed\n",
    "df_dataset.loc[df_dataset['TransactionNo'] == \"00002991-02-2017\", \"Status\"] = -1\n",
    "df_dataset.loc[df_dataset['TransactionNo'] == \"00013593-02-2017\", \"Status\"] = -1\n",
    "df_dataset.loc[df_dataset['TransactionNo'] == \"00033982-05-2017\", \"Status\"] = -1\n",
    "df_dataset.loc[df_dataset['TransactionNo'] == \"00035707-12-2017\", \"Status\"] = -1\n",
    "df_dataset.loc[df_dataset['TransactionNo'] == \"00035966-02-2017\", \"Status\"] = -1\n",
    "df_dataset.loc[df_dataset['TransactionNo'] == \"00036366-04-2017\", \"Status\"] = -1\n",
    "\n",
    "\"\"\" Balance Calculations \"\"\"\n",
    "# Reset balance\n",
    "df_dataset['Balance'] = 0\n",
    "\n",
    "# Create Accounts dataframe\n",
    "df_accounts = df_dataset[['AccountNo', 'Balance']].copy()   # Copy specified columns\n",
    "df_accounts.drop_duplicates(inplace = True)                 # Drop duplicates\n",
    "df_accounts.index = range(len(df_accounts.index))           # Reset index\n",
    "\n",
    "# Loop through each row to re-calculate balances\n",
    "for index in df_dataset.index:\n",
    "    # Get current balance\n",
    "    current_balance = df_accounts.loc[df_accounts['AccountNo'] == df_dataset.loc[index]['AccountNo'], 'Balance'].values[0]\n",
    "\n",
    "    # Check if transaction status is successful\n",
    "    if(df_dataset.loc[index, \"Status\"] == 1):\n",
    "      # Check if transaction is a Credit transaction (outflow of money)\n",
    "      if(pd.isna(df_dataset.loc[index]['Debit'])):\n",
    "          # Update current balance\n",
    "          current_balance -= df_dataset.loc[index]['Credit'] \n",
    "      # Transaction is a Debit transaction (inflow of money)\n",
    "      else: \n",
    "          # Update current balance\n",
    "          current_balance += df_dataset.loc[index]['Debit']\n",
    "    \n",
    "    # Update balances\n",
    "    df_accounts.loc[df_accounts['AccountNo'] == df_dataset.loc[index]['AccountNo'], 'Balance'] = current_balance    # Update account dataframe's balance\n",
    "    df_dataset.at[index, 'Balance'] = current_balance                                                               # Update current row's balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Pickle objects and export dataframes \"\"\"\n",
    "# Export dataframe to excel\n",
    "df_dataset.to_excel(output_dataset_file)\n",
    "df_accounts.to_excel(output_accounts_file)\n",
    "\n",
    "# Pickle dataframe objects\n",
    "pickle_object(df_dataset, pklfile_dataset)\n",
    "pickle_object(df_accounts, pklfile_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>Account</th>\n",
       "      <th>ChequeNo</th>\n",
       "      <th>Date</th>\n",
       "      <th>ValueDate</th>\n",
       "      <th>Debit</th>\n",
       "      <th>Credit</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>409000611074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29/06/2017</td>\n",
       "      <td>29/06/2017</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>TRF FROM  Indiaforensic SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>409000611074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05/07/2017</td>\n",
       "      <td>05/07/2017</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>TRF FROM  Indiaforensic SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>409000611074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18/07/2017</td>\n",
       "      <td>18/07/2017</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>FDRL/INTERNAL FUND TRANSFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>409000611074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/08/2017</td>\n",
       "      <td>01/08/2017</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5500000.0</td>\n",
       "      <td>TRF FRM  Indiaforensic SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>409000611074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16/08/2017</td>\n",
       "      <td>16/08/2017</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>FDRL/INTERNAL FUND TRANSFE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID       Account  ChequeNo        Date   ValueDate      Debit  \\\n",
       "0              1  409000611074       NaN  29/06/2017  29/06/2017  1000000.0   \n",
       "1              2  409000611074       NaN  05/07/2017  05/07/2017  1000000.0   \n",
       "2              3  409000611074       NaN  18/07/2017  18/07/2017   500000.0   \n",
       "3              4  409000611074       NaN  01/08/2017  01/08/2017  3000000.0   \n",
       "4              5  409000611074       NaN  16/08/2017  16/08/2017   500000.0   \n",
       "\n",
       "   Credit    Balance                           Remarks  \n",
       "0     NaN  1000000.0  TRF FROM  Indiaforensic SERVICES  \n",
       "1     NaN  2000000.0  TRF FROM  Indiaforensic SERVICES  \n",
       "2     NaN  2500000.0        FDRL/INTERNAL FUND TRANSFE  \n",
       "3     NaN  5500000.0   TRF FRM  Indiaforensic SERVICES  \n",
       "4     NaN  6000000.0        FDRL/INTERNAL FUND TRANSFE  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preliminary Analysis\n",
    "df_dataset.head()\n",
    "# df_dataset.columns\n",
    "# df_dataset.count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
